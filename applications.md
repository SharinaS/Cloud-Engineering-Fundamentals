# AWS Applications Index

[API Gateway](#API-Gateway)

* [API Caching](#API-Caching)
* [Configure and Deploy](#Configure-and-Deploy)
* [CORS](#CORS)
* [How CORS works](#How-CORS-works)
* [What the API Gateway Can Do](#What-it-Can-Do)

[Elastic Transcoder](#Elastic-Transcoder)

[Kinesis](#Kinesis)

* [About Kinesis](#About-Kinesis)
* [Streaming Data](#Streaming-Data)
* [Three Types of Kinesis](#Three-Types-of-Kinesis)

[SES](#SES)

[SNS](#SNS)

* [Benefits](#Benefits)
* [SQS vs SNS](#SQS-vs-SNS)

[SQS](#SQS)

* [About SQS](#About-SQS)
* [Examples](#Examples)
* [Types of Queues](#Types-of-Queues)
* [Visibility Timeout](#Visibility-Timeout)

[SWF](#SWF)

* [About SWF](#About-SWF)
* [SQS vs SWF](#SQS-vs-SWF)

[Web Identity Federation and Cognito](#Web-Identity-Federation-and-Cognito)

* [User Pools](#User-Pools)

-------
-------

# SQS

SQS = Simple Queue Service

## About SQS

The oldest service in AWS

* SQS comes up a lot in the Solutions Architect exam.

> Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. SQS lets you decouple application components so that they run independently, increasing the overall fault tolerance of the system. Multiple copies of every message are stored redundantly across multiple availability zones so that they are available whenever needed. *- Udemy AWS Certified Cloud Practitioner Practice Exam Course*

SQS is a web service that gives you access to a message queue

* SQS is a queue system - queue can be used to store messages while waiting for a computer to process them
* Lets you store store messages independently from your EC2 instances.

SQS is a distributed queue system

* The queue is a temporary repository for messages that are awaiting processing. 
* Enables web service applications to quickly queue mesages
  * messages are generated by one component in the application and consumed by another application component.


SQS lets you **decouple** the components of an application so they run independently.

* decouple infrastructure
* decouple microservices
* Any component of a distributed application can store messages in a fail-safe queue.
* Anytime you see the word, *decouple*, think SQS!!!

The queue acts as a **buffer**.

* buffering occurs between the component producing and saving data, and the component receiving the data for processing. 
* If the producer is creating work faster than the consumer can process it
* The *producer or consumer* are only intermittently connected to the network

SQS is **pull-based**, versus push-based

* SQS messages must be *pulled* out of the queue by an EC2 instance.
* In contrast, SNS is push-based



### Size

Messages can be *<= 256 KB* of text in any format.

Anything above 256 KB will be stored in S3, versus SQS, up to about 2 gigs in size.

### Time-Frame

Messages can be kept in the queue from 1 minute - 14 days.

*Default* retention period: 4 days.

## Visibility Timeout

The amount of time the message is invisible in the SQS queue *after* a reader picks up that message. 

If the jobs is processed before the visibility timeout expires, the message will be *deleted* from the queue.

If the job is *not* processed before the visibility timeout expires, the message will *become visible again* and another reader will process it. 

* Could result in the same message being delivered twice.
* Longer visibility timeout means the messages don't become visible once obtained by a consumer

Visibility timeout maximum: 12 hours

* If the job is not completed by 12 hours, the message will become visible in the queue again.

### Example exam question

You're getting the same message delivered twice. Why?

The visibility timeout period is not long enough. Increase the length of the timeout period to reduce duplication.


## Types of Queues

* Standard
* FIFO

### Standard

The default type of queue.

Transactions per second: *unlimited*

Guarantee: a message is delivered *at least once*.

* Sometimes more than one copy of a message will be delivered... out of order.
  * due to the highly-distributed architecture that allows high throughput (throughput = rate of production or the rate at which something is processed)
  * Standard queues provide *best-effort ordering*, however, which means that messages are generally delivered in the same order as they are sent.

Application must be able to cope with:

* Messages delivered out of order (occasionally)
* Multiple copies of the same message delivered twice.

Great for applications that can deal with messages occasionally out of order and isn't effected by duplicates.

### FIFO

Complements the standard queue.

Choose FIFO queues when your application can't cope with messages out of sequence or duplicates.

Has *FIFO delivery*: first-in-first-out

* Order in which messages are sent / received is always the same
* Messages are in sequence

Has *exactly-once processing* 

* A message is delivered once and remains available until a consumer processes and deletes it
* Duplicates are never introduced to the queue.

Supports *message groups*

* message groups allow multiple ordered message groups within a single queue.

Transactions per second: limited to *300 transactions / second (TPS)*

* Not as fast as standard queues.

## Amazon SQS Long Polling

A way to retrieve messages from your SQS queues.

Short polling is the regular way to do it. Short polling *returns immediately*, even if the message queue being polled is empty.

Long polling *doesn't return a response until*:

* a message arrives in the message queue,
* or the long poll times out

### Example

You've got a queue that's mostly empty, and you've got EC2 instances polling the queue looking for work.

This costs you money, because for every poll, there's a charge.

Reduce the charges by switching to long polling. It won't return a response until a message enters the queue or until timeout of the poll occurs.

## Examples

### Memes

* User uploads a picture
* S3 receives the picture
* Lambda function is triggered
* Lambda writes some text over the image
* Text is stored in SQS
* A fleet of EC2 instances will:
  * pull the message queue and look for work
  * put the text on the picture stored in S3 to create a meme
  * store the meme on the S3 bucket

SQS serves as a way to store messages independently so that even if an EC2 instance is lost, and can't process the message, another instance will appear and take care of the message being stored in the queue.

### Cheap Fares

Events:

* User goes to an EC2 webserver to search for deal on flights. 
* EC2 instance passes the information to an SQS queue
* Application servers (a fleet) in the background will grab the info in the queue
  * servers will then search for airline deals on various sites. 
* best deals will be collected by the EC2 instances and forwarded to the webserver
* webserver passes the information to the user

If we lose an EC2 instance, another instance will appear, so the search will go on.

# SES

SES = Simple Email Service

Amazon SES (Amazon Simple Email Service) is a flexible, affordable, and highly-scalable email messaging platform for businesses and developers.

# SWF

SWF = Simple Work Flow

Think of SWF if a question refers to human workers and a need to manage that work.

## About SWF

A way of coordinating work across distributed application components... or a way to coordinate work across multiple components of your application.

SWF is a way of coordinating both your applications as well with human beings / manual processes

Task coordination use cases:

* media processing
* web application backends
* busines process workflows
* analysis piopeslines

Tasks are invocations of various processing steps in an application, which are preformed by:

* executable code
* web service calls
* human actions
* scripts

A way of combining the digital environment with human beings.

In SWF, you've gotten a human element to factor into the design process. If there's any sort of manual process, you will be using SWF.

## SWF Actors

### Workflow Starters

An app that can initiate a workflow.

Ie, 

* an e-commere website following the placement of an order
* mobile app searching for bus times

### Deciders

This controls the flow of activity tasks in a workflow execution.

If something has finished / failed in a workflow, a Decider chooses what to do next.

### Activity Workers

These carry out the activity tasks

### SWF Domain

A collection of related workflows.

## SQS vs SWF

The Thing|SQS|SWF|
|-----|-----|-----|
|Timing|Retention period up to 14 days| workflow executions up to 1 year|
|API|message-oriented|*task*-oriented|
|Duplication|Need to handle duplicated messages (default type)|A task is assigned only once and is never duplicated|
|Tracking|Need to implement your own app-level tracking (esp w/multiple queues)|Keeps track of all tasks and events in an app|

# SNS

## About SNS

A web service that works with notifications from the cloud

* set up, operate, send notifications

Lets developers publish messages from an application, to send them to subscribers or applications

* highly scalable
* flexible
* cost-effective

## Send push notifications

* Directly to mobile devices
  * Apple
  * Google
  * Fire OS
  * Windows devices
  * Android devices in China with Baidu Cloud Push
* By SMS text message or email to Amazon Simple Queue Service (SQS) queues
* HTTP endpoint(s)

SNS lets you group multiple recipients using *topics*

* Allows recipients to dynamically subscribe for identical copies of the same notification.
* When you set a billing alert, that's a topic. When you set an autoscaling alert, that's a separate topic.
* One topic supports deliveries to multiple endpoint types.
  * An endpoint type could be a group of iOS, Android and SMS recipients.

Once you create a topic on SNS, an *Amazon Resource Name* is created.

Once you publish to a topic, SNS delivers nicely formatted copies of your message to each subscriber.

## Storage

All messages published to SNS are stored redundantly across multiple AZs -- prevents messages from being lost.

## Benefits

* Push-based delivery (no polling) that is instant
* Simple APIs with reasonably straightforward integration into applications
* Flexible message delivery over multiple transport protocols
* Inexpensive
  * Pay as you go model with no up-front costs
* Point and click interface on the web-based AWS Management Console

## SQS vs SNS

Category|SQS|SNS|
|-----|-----|-----|
|Service Type|messaging|messaging|
|Push or Pull|pull-based (polls) - instances must poll the queue|push-based - messages are pushed out to different devices.|

# Elastic Transcoder

A media transcoder in the cloud

A way to *convert media files* from their original source format into different formats that will play on smartphones, tablets, PCs, etc.

A way of transcoding video.

Has *presets for popular output formats*, meaning you don't need to guess about which settings work best on particular devices.

## Fees

Pay based on

* the minutes you transcode
* The resolution at which you transcode

## Example

* Upload your video to S3
* A lambda function is triggered
* Lambda function looks at all the metadata and sends the video over to Elastic transcoder
* Transcoder looks at the video and transcodes it to look nice on a wide variety of devices.
* Transcoder ships the transcoded videos to another S3 bucket

# API Gateway

> Comes up a lot in the Solutions Architect exam

A fully managed service that works with APIs

* Developers can:
  * publish
  * maintain
  * monitor
  * secure APIs.
* Acts as a *doorway* into your AWS environment to access from your back-end services (EC2, Lambda, web application(s)):
  * data
  * business logic
  * functionality


It will distribute traffic. 

Typical usage: Lambda functions

> Increase performance of the API Gateway:
> * Enable caching
> * Set throttling limits

## How it Works

* Users make a call to the API Gateway from a mobile or desktop, etc source.
* Depending on the call, traffic is passed to:
  * lambda
  * EC2
  * writing to DynamoDB

## What it Can Do

* Define a RESTful API
  * Exposes HTTPS endpoints
* Connect to services like Lambda & DynamoDB - serverless connection!
* Send each API endpoint to a different target
* Runs efficiently w/low cost
* Scales effortlessly 
  * No need for autoscaling groups
* Track and control usage by API key
* Connect to CloudWatch to log all reqeusts for monitoring
* Maintain multiple version of your API
  * Ie, test and dev version versus production API

## Prevent Attacks

You can throttle API Gateway requests to prevent attacks

## CloudWatch

You can log results to CloudWatch

## Configure and Deploy

### How to Configure an API Gateway (theoretical)

1. Define an API (container)
2. Define Resouces and nested resources (URL paths)

For each Resource:

* select supported HTTP methods (verbs)
* set security
* choose target 
  * EC2, lambda, DynamoDB, etc
* set request and response transformations

### How to Deploy (theoretical)

Deploy API to a "stage"

* uses API Gateway domain by default
* or, use a custom domain name

API Gateway supports AWS Certificate Manager, so you can get free SSL/TSL certs.

## API Caching

Enable API caching in API Gateway to cache your endpoint's responses.

API Gateway responds to a request by looking up the endpoint response from the cache, instead of making a request to your endpoint.

### Benefit

* reduce the number of calls made to your endpoint
* improve latency of the requests to your API

### TTL

Responses are cached from your endpont when you enable caching for a stage.

Caching occurs for a specified time-to-live (TTL) period in seconds.

### The Flow of It

* User makes a request
* API Gateway receives the request
* API Gateway sends traffic over to a lambda
* Lambda does things and sends data back to the API Gateway

A second user makes a request that is identical to the prior one.

* API Gateway finds the cached response, skips sending stuff over to the lambda, and returns a response to the user.

# CORS 

CORS = Cross Origin Resource Sharing

## Same Origin Policy

A concept in the web application security model.

States that *if two web pages have the same origin*, a web browser can permit scripts contained in one web page to access data in a second web page.

* They must have the same domain name

Same-origin policy is done to prevent Cross-Site Scripting (XSS) attacks.

* One web site attacks another website
* Postman and curl ignore Same Origin Policy

Note that in AWS, we are constantly using different domain names - S3 has a different domain name than Cloudfront, which is different from the API Gateway domain name, etc.

## About CORS

A way to bypass Same-Origin Policy - One way the server at the other end (not the client code in the browser) can relax the same-origin policy.

CORS allows restricted resources on Domain A's web page to be requested from Bomain B - outside Domain A.

* ie, fonts on the webpage

Allows one domain to talk to another domain and request resources from that other domain.  

Cors is *enforced by the client's* browser

### JS / AJAX and Multiple Domains

If you're using Javascript/AJAX that uses multiple domains with API Gateway, make sure to enable CORS on API Gateway.

## How CORS works

Browser makes an HTTP OPTIONS call for a URL

* OPTIONS is an HTTP method like GET, PUT, POST, etc

Server returns a response that says:

* "these other domains are approved to GET this URL"

Error message may show up:

* "Origin policy cannot be read at the remote resource"

    ^-- This error message means you *need to enable CORS* on the API Gateway. 

# Kinesis

## Streaming Data

Data that is generated continuously from thousands of data sources.

* Data sources send in the data records simultaneously, in small sizes (in kilobytes)

Examples:

* Purchases from online stores
  * unique item id, and other transactional data
* Stock prices
* Game data (as the gamer plays)
  * level achieved
* Social network data
* Geospatial data
  * Where you are on the map
  * Traffic
* iOT sensor data
  * sensors used on a farm

## About Kinesis

A platform on AWS to send streaming data to. 

You can load the data and analyze it, and build custom applications for a business' needs.

## Three Types of Kinesis

### Kinesis Streams

Various devices, EC2, iOT, etc are the data producers.

The data producers stream the data to Kinesis Streams. 

Kinesis Streams stores the data in *shards*

> Kinesis Streams is the only type that has shards! And, data persistence!

* Storage time: 24 hours - 7 days
* Shards: What the data is stored in
  * Each type of data is stored in a different shard
  * Reads: 5 transactions / sec 
  * Read rate: max total data read rate of 2 MB / sec 
  * Writes: Up to 1,000 records / sec 
  * Write rate: max total data write rate of 1 MB / sec (including partition keys)

 Data Consumers: EC2 instances that the data in the Shards is sent to for analysis (outside of Kinesis Streams). Data is stored in the Shards while analysis is occurring.

After analysis, the data is sent from the consumers to a variety of places that the EC2 instances can access

* DynamoDB
* S3
* EMR
* Redshift
* RDS

Key components of Kinesis Streams:

* Producers
* Shards
* Consumers

Data Capacity of the Stream

* A function of the number of shards that you specify for the stream.
* Total capacity = sum of the capacities of the shards

### Kinesis Firehose

Various devices, EC2, iOT, etc are the data producers.

The data producers stream the data to Kinesis Firehose.

There is *no persistant storage* inside K. Firehose. The data has to be analyzed time of!

* Can have lambda functions inside the firehose. 
  * When the data comes in, the lambda is triggered, and the function runs a particular block of code for that data.

Data is then outputted from Firehose.

* It can be outputted directly to S3
* It can be outputted to Redshift via S3
* Elastic search cluster

The easiest way to load streaming data into data stores and analytics tools

* Can capture, transform and load streaming data into S3, Redshift, Elasticsearch Service, Splunk.

Key components of Kinesis Firehose:

* Delivery streams
* Records of data and destinations

### Kinesis Analytics

Works with both Streams and Firehose. 

Can analyze the data on the fly *inside Kinesis* (of either type).

Data is then stored on S3, Redshift or Elastic Search Cluster.

# Web Identity Federation and Cognito

## Web Identity Federation

Your users are allowed to gain access to AWS resources after they authenticate with a **Web Identity Provider** (Amazon, FB, Google). 

The user receives an authentication code after successful authentication from the **Web ID provider**. They can then trade that code for temporary security credentials.

Ultimately just lets you sign into a website using your FB or Google credentials, etc. 

## Cognito 

> A Web IDentity Federation service

Allows you to sign-in / sign-up to your apps

Allows access for guest users

Cognito acts as an **Identity Broker** between your app and *Web ID providers*, so you don't need to write extra code.

Synchronizes user data from multiple devices

* If you change the username on one device, it will trickle out to your other devices.

Recommended for all mobile applications with AWS services.

### Recommended Approach

Say you have a website with:

* Lambda
* DynamoDB
* S3

Series of events:

* User will authenticate with FB (for example). 
* FB gives the user an authentication token
* User sends auth token to cognito
* Cognito responds and grants access to the AWS env't (depending on the access yout permit)
* User can start lambda functions, store data in the DB or store images in S3, etc

### Benefits of Cognito

* No need for the app to imbed or store AWS credentials on the device
* Users get a seamless experience across all mobile devices

### User Pools

> Takes care of the user side of authentication - usernames, passwords, registration

They are directories that manage sign-up and sign-in functionality for mobile and web apps.

Users can sign-in directly to the User Pool - username/password is stored within Cognito itself.

Or, users can sign-in using FB, Amazon or Google - third party.

* Cognito acts as an *Identity Broker* between the identity provider and AWS. 
* Successful authentication generates a JSON Web token (JWT). 

### Identity Pools

> Takes care of authorizing access to AWS resources - the actual granting of authentication

Provide *temporary* AWS credentials to access AWS services like S3 or DynamoDB.

### Step-by-Step

* User logs in using FB account
* FB authenticates her and passes back an authentication token to Cognito.
* Cognito converts that token to a JWT
* User sends the JWT to an Identity Pool
* Identity Pool grants the user credentials in the form of an IAM role
* User can access AWS resources

### Cognito Synchronisation

Cognito uses Push Synchronization to push updates and synchronize user data across multiple devices.

Uses *SNS* to send a notification to all devices associated with a given user identity whenever data stored in the cloud changes.
